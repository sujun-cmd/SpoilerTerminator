import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

# --- 1. åŠ è½½ç°ä»£ LLM ---
# Qwen2.5-7B-Instruct: ç›®å‰å¼€æºç•Œ 7B å‚æ•°ä¸‹çš„æœ€å¼ºæ¨¡å‹ï¼ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›æå¼º
model_id = "Qwen/Qwen2.5-7B"

print(f"ğŸš€ æ­£åœ¨åŠ è½½ LLM: {model_id} ...")

# åŠ è½½ Tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_id)

# åŠ è½½æ¨¡å‹ (V100 æ˜¾å­˜è¶³å¤Ÿè·‘ fp16)
# device_map="auto" ä¼šè‡ªåŠ¨æŠŠæ¨¡å‹å¡è¿› GPU
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    device_map="auto"
)

# --- 2. å®šä¹‰æ™ºèƒ½æ”¹å†™å‡½æ•° ---
def despoil_with_llm(spoiler_text):
    # ä½¿ç”¨ Chat æ ¼å¼çš„ Prompt
    messages = [
        {"role": "system", "content": "You are a professional movie editor. Your task is to rewrite movie spoilers into vague, suspenseful plot teasers for a synopsis. Never reveal who dies, who the killer is, or the specific ending. Make it sound mysterious."},
        {"role": "user", "content": f"Rewrite this spoiler into a safe teaser: '{spoiler_text}'"}
    ]
    
    # æ„å»º Prompt
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
    
    # ç”Ÿæˆ
    generated_ids = model.generate(
        **model_inputs,
        max_new_tokens=128,
        temperature=0.7,   # ç¨å¾®ä¸€ç‚¹åˆ›é€ åŠ›
        top_p=0.9,
        do_sample=True
    )
    
    # æå–å›ç­” (å»æ‰ Prompt éƒ¨åˆ†)
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]
    
    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return response

# --- 3. æµ‹è¯•æ•ˆæœ ---
test_spoilers = [
    "Bruce Willis is actually a ghost in the end.",
    "Darth Vader reveals that he is Luke's father.",
    "She dies in the car accident.",
    "The killer turns out to be the detective investigating the case.",
    "They all die at the end of the movie."
]

print("\n" + "="*100)
print(f"{'Original Spoiler':<50} | {'LLM Despoiled Version (Teaser)'}")
print("="*100)

for spoiler in test_spoilers:
    safe_version = despoil_with_llm(spoiler)
    # æ¸…ç†ä¸€ä¸‹è¾“å‡ºï¼Œé˜²æ­¢æ¨¡å‹è¯ç—¨
    safe_version = safe_version.replace('"', '').strip()
    print(f"{spoiler:<50} | {safe_version}")
    print("-" * 100)



