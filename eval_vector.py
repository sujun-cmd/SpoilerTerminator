import os
import torch
import numpy as np
import joblib
from datasets import load_dataset
from nltk.tokenize import sent_tokenize
import nltk
from sentence_transformers import SentenceTransformer
from sklearn.metrics import classification_report, f1_score

# --- ç¯å¢ƒè®¾ç½® ---
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
    nltk.download('punkt_tab')

current_dir = os.path.dirname(os.path.abspath(__file__))
model_dir = os.path.join(current_dir, "vector_models")

# --- 1. åŠ è½½æ¨¡å‹ ---
print("æ­£åœ¨åŠ è½½ä¿å­˜çš„åˆ†ç±»å™¨...")
clf_path = os.path.join(model_dir, "spoiler_direction_clf.pkl")
if not os.path.exists(clf_path):
    print("é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ train_vector.py")
    exit()

clf = joblib.load(clf_path)

print("æ­£åœ¨åŠ è½½å¥å‘é‡æ¨¡å‹...")
embed_model = SentenceTransformer('all-mpnet-base-v2')
if torch.cuda.is_available():
    embed_model = embed_model.to('cuda')

# --- 2. å‡†å¤‡æµ‹è¯•æ•°æ® (å…³é”®ä¿®æ”¹) ---
print("æ­£åœ¨å‡†å¤‡æµ‹è¯•é›†...")
raw_dataset = load_dataset("bhavyagiri/imdb-spoiler")

# [å…³é”®ä¿®æ”¹] ä½¿ç”¨å’Œè®­ç»ƒé›†ä¸€æ¨¡ä¸€æ ·çš„åˆ‡åˆ†æ–¹å¼
split = raw_dataset["train"].train_test_split(test_size=0.2, seed=42)
test_data = split["test"]  # æ‹¿å‡ºå¦å¤– 20% ä½œä¸ºæµ‹è¯•é›†

print(f"æµ‹è¯•é›†æ–‡æ¡£æ•°: {len(test_data)}")

test_sentences = []
test_labels = []

for text, doc_label in zip(test_data["text"], test_data["label"]):
    sents = sent_tokenize(text)
    for sent in sents:
        if len(sent) < 10: continue
        test_sentences.append(sent)
        test_labels.append(doc_label)

# --- 3. é¢„æµ‹ä¸è¯„ä¼° ---
print(f"æ­£åœ¨è®¡ç®— {len(test_sentences)} ä¸ªå¥å­çš„å‘é‡...")
X_test = embed_model.encode(test_sentences, batch_size=64, show_progress_bar=True)

print("æ­£åœ¨æ¨ç†...")
y_pred = clf.predict(X_test)
y_probs = clf.predict_proba(X_test)[:, 1]

# --- 4. è¾“å‡ºæŒ‡æ ‡ ---
print("\n" + "="*40)
print("Evaluation Report (Sentence Level)")
print("="*40)

# ä½¿ç”¨ 0.5 é˜ˆå€¼
print(classification_report(test_labels, y_pred, target_names=["Safe", "Spoiler"]))

f1 = f1_score(test_labels, y_pred)
print(f"Final F1 Score: {f1:.4f}")

# --- 5. ç²¾å½©æ—¶åˆ» ---
print("\n" + "="*40)
print("æ¨¡å‹è®¤ä¸ºæœ€å‰§é€çš„å¥å­ (Top Spoilers Detected)")
print("="*40)

top_indices = np.argsort(y_probs)[-10:][::-1]

for idx in top_indices:
    sent = test_sentences[idx]
    score = y_probs[idx]
    # æ³¨æ„ï¼šè¿™é‡Œçš„ labels æ˜¯å¼±æ ‡ç­¾ï¼ˆæ–‡æ¡£æ ‡ç­¾ï¼‰ï¼Œä»…ä¾›å‚è€ƒ
    true_label = "Spoiler Doc" if test_labels[idx] == 1 else "Safe Doc"
    print(f"Score: {score:.4f} | [{true_label}] {sent}")

print("\n" + "="*40)
print("è‡ªå®šä¹‰æµ‹è¯•ç”¨ä¾‹")
print("="*40)
custom_sents = [
    "The camera work is fantastic.",
    "Bruce Willis is a ghost.",
    "He dies at the end.",
    "It was a boring movie."
]
custom_vecs = embed_model.encode(custom_sents)
custom_probs = clf.predict_proba(custom_vecs)[:, 1]

for sent, prob in zip(custom_sents, custom_probs):
    label = "ğŸš¨ SPOILER" if prob > 0.5 else "âœ… SAFE"
    print(f"[{prob:.4f}] {label} : {sent}")
