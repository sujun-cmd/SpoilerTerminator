import os
import time
import torch
import joblib
import numpy as np
import evaluate
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, f1_score, precision_score, recall_score

# --- 0. ç¯å¢ƒè®¾ç½® ---
device = 0 if torch.cuda.is_available() else -1
current_dir = os.path.dirname(os.path.abspath(__file__))

# è·¯å¾„ (æ ¹æ®ä½ å®é™…ä¿å­˜çš„è·¯å¾„ä¿®æ”¹)
lr_model_path = os.path.join(current_dir, "vector_models", "spoiler_direction_clf.pkl")
roberta_model_path = os.path.join(current_dir, "spoiler_roberta_final") # Self-Training åçš„æ¨¡å‹

# --- 1. åŠ è½½æ¨¡å‹ ---
print("ğŸ¥Š æ­£åœ¨åŠ è½½é€‰æ‰‹...")

# é€‰æ‰‹ 1: LR (Teacher)
print("Load: LR + MPNet...")
try:
    lr_clf = joblib.load(lr_model_path)
    embed_model = SentenceTransformer('all-mpnet-base-v2')
    if torch.cuda.is_available():
        embed_model = embed_model.to('cuda')
except Exception as e:
    print(f"LR æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    exit()

# é€‰æ‰‹ 2: RoBERTa (Student)
print("Load: RoBERTa Student...")
try:
    # æ˜¾å¼åŠ è½½ï¼Œç¡®ä¿ä½¿ç”¨ GPU
    tokenizer = AutoTokenizer.from_pretrained(roberta_model_path)
    model = AutoModelForSequenceClassification.from_pretrained(roberta_model_path)
    roberta_pipe = pipeline("text-classification", model=model, tokenizer=tokenizer, device=device, truncation=True, max_length=128)
except Exception as e:
    print(f"RoBERTa æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    exit()

# --- 2. åŠ è½½é«˜è´¨é‡æµ‹è¯•é›† (Goodreads) ---
print("\nğŸ“š æ­£åœ¨åŠ è½½ Goodreads å›¾ä¹¦è¯„è®ºæ•°æ® (è·¨åŸŸæµ‹è¯•)...")
# æˆ‘ä»¬åªå–å…¶ä¸­çš„ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•ï¼Œå› ä¸ºæ•°æ®é›†å¤ªå¤§äº†
# Goodreads æ•°æ®é›†ç»“æ„é€šå¸¸åŒ…å« 'review_sentences' å’Œ 'has_spoiler' æ ‡è®°
try:
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ streaming æ¨¡å¼åŠ è½½ï¼Œåªå–å‰ 2000 ä¸ªæ ·æœ¬ï¼Œé˜²æ­¢å†…å­˜çˆ†ç‚¸
    dataset = load_dataset("wanng/goodreads-spoiler", split="test", streaming=True)
except:
    print("ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®é›†...")
    # å¤‡ç”¨æ–¹æ¡ˆï¼šå¦‚æœ wanng çš„æºè¿ä¸ä¸Šï¼Œå¯ä»¥ç”¨ yelp æˆ–å…¶ä»–ï¼Œè¿™é‡Œå‡è®¾èƒ½è¿ä¸Š
    exit()

test_sentences = []
test_labels = []

print("æ­£åœ¨æ„å»ºæµ‹è¯•é›† (æå–å¥å­çº§æ ‡ç­¾)...")
# è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œæˆ‘ä»¬å–å¤Ÿ 5000 ä¸ªå¥å­å°±åœ
counter = 0
MAX_SAMPLES = 5000

for example in dataset:
    # Goodreads æ•°æ®é›†çš„å­—æ®µé€šå¸¸æ˜¯ 'review_sentences' (list of str) å’Œ 'has_spoiler' (list of bool/int)
    # å…·ä½“å­—æ®µåéœ€è¦ print(example) ç¡®è®¤ï¼Œä»¥ä¸‹æ˜¯å¸¸è§ç»“æ„
    try:
        sents = example.get('review_sentences', [])
        labels = example.get('has_spoiler', [])
        
        if len(sents) != len(labels): continue
        
        for s, l in zip(sents, labels):
            if len(s) < 10: continue # è¿‡æ»¤çŸ­å¥
            test_sentences.append(s)
            test_labels.append(int(l)) # 0 æˆ– 1
            counter += 1
    except:
        continue
        
    if counter >= MAX_SAMPLES:
        break

print(f"âœ… æµ‹è¯•é›†æ„å»ºå®Œæˆ: {len(test_sentences)} å¥")
print(f"   å‰§é€å¥: {sum(test_labels)}")
print(f"   æ­£å¸¸å¥: {len(test_labels) - sum(test_labels)}")

if sum(test_labels) == 0:
    print("âš ï¸ è­¦å‘Š: æµ‹è¯•é›†é‡Œæ²¡æœ‰å‰§é€å¥ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†å­—æ®µç»“æ„ã€‚")
    # å¦‚æœ wanng æ•°æ®é›†åŠ è½½æœ‰é—®é¢˜ï¼Œå¯ä»¥æ‰‹åŠ¨ mock ä¸€äº›æ•°æ®æµ‹è¯•æµç¨‹
    exit()

# --- 3. æ¯”èµ›å¼€å§‹ ---

# === Round 1: LR æ¨¡å‹ ===
print("\nğŸ”¥ Round 1: LR (Vector) Model æ¨ç†ä¸­...")
start_time = time.time()

# 1. è®¡ç®—å‘é‡
vecs = embed_model.encode(test_sentences, batch_size=128, show_progress_bar=True)
# 2. é¢„æµ‹
lr_preds = lr_clf.predict(vecs)

lr_time = time.time() - start_time
print(f"LR è€—æ—¶: {lr_time:.2f} ç§’")

# === Round 2: RoBERTa æ¨¡å‹ ===
print("\nğŸ”¥ Round 2: RoBERTa (Student) Model æ¨ç†ä¸­...")
start_time = time.time()

# pipeline è‡ªåŠ¨å¤„ç† batch
roberta_results = roberta_pipe(test_sentences, batch_size=64) 
roberta_preds = [1 if res['label'] == 'LABEL_1' else 0 for res in roberta_results]

roberta_time = time.time() - start_time
print(f"RoBERTa è€—æ—¶: {roberta_time:.2f} ç§’")

# --- 4. ç»“æœå¯¹æ¯”ä¸ç»“ç®— ---

def print_metrics(name, y_true, y_pred, time_taken):
    print(f"\nğŸ“Š {name} æˆç»©å•")
    print("-" * 30)
    print(f"æ¨ç†é€Ÿåº¦ (QPS): {len(y_true)/time_taken:.2f} sentences/sec")
    p = precision_score(y_true, y_pred)
    r = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    acc = np.mean(np.array(y_true) == np.array(y_pred))
    
    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {p:.4f}")
    print(f"Recall:    {r:.4f}")
    print(f"F1 Score:  {f1:.4f}")

print("\n" + "="*50)
print("ğŸ† æœ€ç»ˆå¯¹å†³ç»“æœ (Movie Models tested on Book Reviews)")
print("="*50)

print_metrics("LR Teacher (MPNet)", test_labels, lr_preds, lr_time)
print_metrics("RoBERTa Student", test_labels, roberta_preds, roberta_time)

print("="*50)

# --- 5. é”™è¯¯æ¡ˆä¾‹åˆ†æ (è°åœ¨è£¸æ³³ï¼Ÿ) ---
print("\nğŸ” å·®å¼‚æ ·æœ¬åˆ†æ (Disagreement Analysis)")
count = 0
for i in range(len(test_sentences)):
    if count >= 5: break
    # æ‰¾ä¸€ä¸ª LR å¯¹äº†ä½† RoBERTa é”™äº†ï¼Œæˆ–è€…åè¿‡æ¥çš„ä¾‹å­
    if lr_preds[i] != roberta_preds[i] and test_labels[i] == 1:
        print("-" * 30)
        print(f"å¥å­: {test_sentences[i]}")
        print(f"çœŸå®æ ‡ç­¾: {test_labels[i]}")
        print(f"LR é¢„æµ‹: {lr_preds[i]}")
        print(f"RoBERTa é¢„æµ‹: {roberta_preds[i]}")
        count += 1
